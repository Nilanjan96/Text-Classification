{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reuters2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UKBHB-lGAyo",
        "colab_type": "code",
        "outputId": "ac3e16cc-6a82-4172-f20d-a28dbb656388",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "from keras.datasets import reuters\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_features = 2000  # number of words to consider as features\n",
        "maxlen = 500  # cut texts after this number of words (among top max_features most common words)\n",
        "batch_size = 64\n",
        "\n",
        "print('Loading data...')\n",
        "(input_train, y_train), (input_test, y_test) = reuters.load_data(num_words=max_features)\n",
        "print(len(input_train), 'train sequences')\n",
        "print(len(input_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
        "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
        "print('input_train shape:', input_train.shape)\n",
        "print('input_test shape:', input_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "8982 train sequences\n",
            "2246 test sequences\n",
            "Pad sequences (samples x time)\n",
            "input_train shape: (8982, 500)\n",
            "input_test shape: (2246, 500)\n",
            "y_train shape: (8982,)\n",
            "y_test shape: (2246,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuXPxTXSGHe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, 46)\n",
        "y_test = np_utils.to_categorical(y_test, 46)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi39-NQcGM83",
        "colab_type": "code",
        "outputId": "32edc200-f328-42f4-9668-14ead14a7715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2246, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4dvj3rpSct3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN\n",
        "from keras.layers import Dense\n",
        "from keras import regularizers\n",
        "from keras import models\n",
        "from keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXtGAGF1GP_3",
        "colab_type": "code",
        "outputId": "a22a0bec-a3fe-4e91-edd0-fdcf9d359103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 64))\n",
        "model.add(SimpleRNN(64, return_sequences=True))\n",
        "model.add(SimpleRNN(64, return_sequences=True))\n",
        "model.add(SimpleRNN(64, return_sequences=True))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "history = model.fit(input_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.3)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 6287 samples, validate on 2695 samples\n",
            "Epoch 1/10\n",
            "1664/6287 [======>.......................] - ETA: 31s - loss: 3.4176 - acc: 0.1671"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-beff2f73c36d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     validation_split=0.3)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax_U_MXtGSTP",
        "colab_type": "code",
        "outputId": "fc9fbf58-ffb8-4b35-d60c-1be9e37a283a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "\n",
        "l2_model = models.Sequential()\n",
        "l2_model.add(Embedding(10000, 16))\n",
        "l2_model.add(SimpleRNN(16,kernel_regularizer=regularizers.l2(0.001)))\n",
        "l2_model.add(Dense(46, activation='softmax'))\n",
        "\n",
        "l2_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "l2_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "simple_rnn_5 (SimpleRNN)     (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 46)                782       \n",
            "=================================================================\n",
            "Total params: 161,310\n",
            "Trainable params: 161,310\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9LW6NUDIVhx",
        "colab_type": "code",
        "outputId": "4a3103e1-bb0e-4285-9994-c7f25d4ff643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        }
      },
      "source": [
        "l2_model_hist = l2_model.fit(input_train, y_train, epochs=25,batch_size=32,validation_data=(input_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8982 samples, validate on 2246 samples\n",
            "Epoch 1/25\n",
            "8982/8982 [==============================] - 27s 3ms/step - loss: 2.6597 - acc: 0.3285 - val_loss: 2.3915 - val_acc: 0.3620\n",
            "Epoch 2/25\n",
            "8982/8982 [==============================] - 26s 3ms/step - loss: 2.3130 - acc: 0.3640 - val_loss: 2.2897 - val_acc: 0.3736\n",
            "Epoch 3/25\n",
            "8982/8982 [==============================] - 26s 3ms/step - loss: 2.2026 - acc: 0.3896 - val_loss: 2.2358 - val_acc: 0.3936\n",
            "Epoch 4/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 2.1188 - acc: 0.4213 - val_loss: 2.2197 - val_acc: 0.4087\n",
            "Epoch 5/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 2.0030 - acc: 0.4809 - val_loss: 2.1399 - val_acc: 0.4804\n",
            "Epoch 6/25\n",
            "8982/8982 [==============================] - 24s 3ms/step - loss: 1.8827 - acc: 0.5229 - val_loss: 2.1238 - val_acc: 0.4831\n",
            "Epoch 7/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.7805 - acc: 0.5477 - val_loss: 2.1190 - val_acc: 0.4889\n",
            "Epoch 8/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.7351 - acc: 0.5568 - val_loss: 2.2362 - val_acc: 0.4648\n",
            "Epoch 9/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.8465 - acc: 0.5332 - val_loss: 2.1724 - val_acc: 0.4822\n",
            "Epoch 10/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.6558 - acc: 0.5764 - val_loss: 2.1568 - val_acc: 0.4920\n",
            "Epoch 11/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.5818 - acc: 0.5935 - val_loss: 2.1519 - val_acc: 0.4964\n",
            "Epoch 12/25\n",
            "8982/8982 [==============================] - 24s 3ms/step - loss: 1.5178 - acc: 0.6057 - val_loss: 2.2257 - val_acc: 0.4720\n",
            "Epoch 13/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.4607 - acc: 0.6188 - val_loss: 2.1523 - val_acc: 0.4915\n",
            "Epoch 14/25\n",
            "8982/8982 [==============================] - 24s 3ms/step - loss: 1.4249 - acc: 0.6284 - val_loss: 2.2222 - val_acc: 0.4786\n",
            "Epoch 15/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.3816 - acc: 0.6372 - val_loss: 2.2236 - val_acc: 0.4813\n",
            "Epoch 16/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.3321 - acc: 0.6507 - val_loss: 2.3056 - val_acc: 0.4599\n",
            "Epoch 17/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.3214 - acc: 0.6522 - val_loss: 2.2671 - val_acc: 0.4684\n",
            "Epoch 18/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.2783 - acc: 0.6635 - val_loss: 2.2619 - val_acc: 0.4866\n",
            "Epoch 19/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.2431 - acc: 0.6749 - val_loss: 2.3224 - val_acc: 0.4764\n",
            "Epoch 20/25\n",
            "8982/8982 [==============================] - 26s 3ms/step - loss: 1.2178 - acc: 0.6839 - val_loss: 2.2889 - val_acc: 0.4822\n",
            "Epoch 21/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.2089 - acc: 0.6825 - val_loss: 2.2751 - val_acc: 0.4920\n",
            "Epoch 22/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.1707 - acc: 0.6952 - val_loss: 2.3489 - val_acc: 0.4817\n",
            "Epoch 23/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.1387 - acc: 0.7065 - val_loss: 2.3123 - val_acc: 0.5009\n",
            "Epoch 24/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.1113 - acc: 0.7112 - val_loss: 2.3831 - val_acc: 0.4898\n",
            "Epoch 25/25\n",
            "8982/8982 [==============================] - 25s 3ms/step - loss: 1.0854 - acc: 0.7214 - val_loss: 2.3932 - val_acc: 0.4853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2V258b3I7Oe",
        "colab_type": "code",
        "outputId": "bc5385be-6624-4922-ba93-601d97b0122d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "model3 = models.Sequential()\n",
        "model3.add(Embedding(10000, 80))\n",
        "model3.add(SimpleRNN(80))\n",
        "model3.add(Dense(46, activation='softmax'))\n",
        "\n",
        "model3.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "model3.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 80)          800000    \n",
            "_________________________________________________________________\n",
            "simple_rnn_6 (SimpleRNN)     (None, 80)                12880     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 46)                3726      \n",
            "=================================================================\n",
            "Total params: 816,606\n",
            "Trainable params: 816,606\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul6gkjsXIoox",
        "colab_type": "code",
        "outputId": "508994be-25a0-4f89-fb2d-0a1c2ea65e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        }
      },
      "source": [
        "model3.fit(input_train, y_train, epochs=25,\n",
        "                        batch_size=16,validation_data=(input_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8982 samples, validate on 2246 samples\n",
            "Epoch 1/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 2.3120 - acc: 0.4161 - val_loss: 2.2866 - val_acc: 0.3909\n",
            "Epoch 2/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 1.8769 - acc: 0.5077 - val_loss: 1.8854 - val_acc: 0.5289\n",
            "Epoch 3/25\n",
            "8982/8982 [==============================] - 67s 7ms/step - loss: 1.5762 - acc: 0.5984 - val_loss: 1.8765 - val_acc: 0.5361\n",
            "Epoch 4/25\n",
            "8982/8982 [==============================] - 69s 8ms/step - loss: 1.3675 - acc: 0.6555 - val_loss: 1.9535 - val_acc: 0.5512\n",
            "Epoch 5/25\n",
            "8982/8982 [==============================] - 69s 8ms/step - loss: 1.1604 - acc: 0.7055 - val_loss: 1.9679 - val_acc: 0.5160\n",
            "Epoch 6/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 0.9749 - acc: 0.7570 - val_loss: 2.0228 - val_acc: 0.5347\n",
            "Epoch 7/25\n",
            "8982/8982 [==============================] - 69s 8ms/step - loss: 0.8223 - acc: 0.7971 - val_loss: 2.0104 - val_acc: 0.5490\n",
            "Epoch 8/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 0.7228 - acc: 0.8198 - val_loss: 2.1782 - val_acc: 0.5183\n",
            "Epoch 9/25\n",
            "8982/8982 [==============================] - 69s 8ms/step - loss: 0.6166 - acc: 0.8519 - val_loss: 2.1189 - val_acc: 0.5490\n",
            "Epoch 10/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 0.5450 - acc: 0.8701 - val_loss: 2.2171 - val_acc: 0.5321\n",
            "Epoch 11/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 0.4902 - acc: 0.8819 - val_loss: 2.3693 - val_acc: 0.5058\n",
            "Epoch 12/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 0.4325 - acc: 0.8966 - val_loss: 2.2713 - val_acc: 0.5254\n",
            "Epoch 13/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 0.4044 - acc: 0.9046 - val_loss: 2.3212 - val_acc: 0.5289\n",
            "Epoch 14/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 0.3715 - acc: 0.9092 - val_loss: 2.4903 - val_acc: 0.5049\n",
            "Epoch 15/25\n",
            "8982/8982 [==============================] - 69s 8ms/step - loss: 0.3469 - acc: 0.9163 - val_loss: 2.4956 - val_acc: 0.4951\n",
            "Epoch 16/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 0.3172 - acc: 0.9225 - val_loss: 2.4901 - val_acc: 0.5045\n",
            "Epoch 17/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 0.3007 - acc: 0.9253 - val_loss: 2.4945 - val_acc: 0.5031\n",
            "Epoch 18/25\n",
            "8982/8982 [==============================] - 69s 8ms/step - loss: 0.2907 - acc: 0.9263 - val_loss: 2.5668 - val_acc: 0.4978\n",
            "Epoch 19/25\n",
            "8982/8982 [==============================] - 69s 8ms/step - loss: 0.2655 - acc: 0.9299 - val_loss: 2.4589 - val_acc: 0.5245\n",
            "Epoch 20/25\n",
            "8982/8982 [==============================] - 69s 8ms/step - loss: 0.2589 - acc: 0.9309 - val_loss: 2.6201 - val_acc: 0.4817\n",
            "Epoch 21/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 0.2442 - acc: 0.9350 - val_loss: 2.4918 - val_acc: 0.5027\n",
            "Epoch 22/25\n",
            "8982/8982 [==============================] - 69s 8ms/step - loss: 0.2307 - acc: 0.9385 - val_loss: 2.5436 - val_acc: 0.5196\n",
            "Epoch 23/25\n",
            "8982/8982 [==============================] - 69s 8ms/step - loss: 0.2142 - acc: 0.9409 - val_loss: 2.5742 - val_acc: 0.5174\n",
            "Epoch 24/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 0.2137 - acc: 0.9397 - val_loss: 2.5632 - val_acc: 0.5134\n",
            "Epoch 25/25\n",
            "8982/8982 [==============================] - 68s 8ms/step - loss: 0.2093 - acc: 0.9420 - val_loss: 2.6437 - val_acc: 0.4969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f71abc392e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtX-Y52gLp5H",
        "colab_type": "code",
        "outputId": "7055bfbc-a893-415a-a800-35d0ae687999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "dpt_model = models.Sequential()\n",
        "dpt_model.add(Embedding(2000, 32))\n",
        "dpt_model.add(layers.Dropout(0.5))\n",
        "dpt_model.add(SimpleRNN(16,kernel_regularizer=regularizers.l2(0.001)))\n",
        "dpt_model.add(layers.Dropout(0.5))\n",
        "dpt_model.add(Dense(46, activation='softmax'))\n",
        "\n",
        "dpt_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "dpt_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 32)          64000     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "simple_rnn_5 (SimpleRNN)     (None, 16)                784       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 46)                782       \n",
            "=================================================================\n",
            "Total params: 65,566\n",
            "Trainable params: 65,566\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H5ZGGe0QSt1",
        "colab_type": "code",
        "outputId": "08c6df3a-d084-4515-9be5-b09245ca52fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        }
      },
      "source": [
        "dpt_model.fit(input_train, y_train,\n",
        "                               epochs=80,\n",
        "                               batch_size=32,\n",
        "                               validation_data=(input_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 8982 samples, validate on 2246 samples\n",
            "Epoch 1/80\n",
            "8982/8982 [==============================] - 31s 3ms/step - loss: 2.8017 - acc: 0.2810 - val_loss: 2.4258 - val_acc: 0.3620\n",
            "Epoch 2/80\n",
            "8982/8982 [==============================] - 30s 3ms/step - loss: 2.4803 - acc: 0.3491 - val_loss: 2.2847 - val_acc: 0.3682\n",
            "Epoch 3/80\n",
            "8982/8982 [==============================] - 31s 3ms/step - loss: 2.2409 - acc: 0.3717 - val_loss: 2.0398 - val_acc: 0.3980\n",
            "Epoch 4/80\n",
            "8982/8982 [==============================] - 31s 3ms/step - loss: 2.0897 - acc: 0.3947 - val_loss: 1.9586 - val_acc: 0.4092\n",
            "Epoch 5/80\n",
            "8982/8982 [==============================] - 31s 3ms/step - loss: 2.0141 - acc: 0.4037 - val_loss: 1.9347 - val_acc: 0.4199\n",
            "Epoch 6/80\n",
            "8982/8982 [==============================] - 31s 3ms/step - loss: 1.9783 - acc: 0.4200 - val_loss: 1.9231 - val_acc: 0.4608\n",
            "Epoch 7/80\n",
            "8982/8982 [==============================] - 30s 3ms/step - loss: 1.9376 - acc: 0.4375 - val_loss: 1.9037 - val_acc: 0.4559\n",
            "Epoch 8/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.9147 - acc: 0.4436 - val_loss: 1.8835 - val_acc: 0.4608\n",
            "Epoch 9/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.8894 - acc: 0.4579 - val_loss: 1.8924 - val_acc: 0.4653\n",
            "Epoch 10/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.8742 - acc: 0.4582 - val_loss: 1.8676 - val_acc: 0.4653\n",
            "Epoch 11/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.8502 - acc: 0.4747 - val_loss: 1.8770 - val_acc: 0.4533\n",
            "Epoch 12/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.8347 - acc: 0.4820 - val_loss: 1.8649 - val_acc: 0.4537\n",
            "Epoch 13/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.8252 - acc: 0.4797 - val_loss: 2.0131 - val_acc: 0.4497\n",
            "Epoch 14/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.8027 - acc: 0.4933 - val_loss: 1.8758 - val_acc: 0.4550\n",
            "Epoch 15/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.7945 - acc: 0.4989 - val_loss: 1.8769 - val_acc: 0.4635\n",
            "Epoch 16/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.7684 - acc: 0.5032 - val_loss: 1.8889 - val_acc: 0.4492\n",
            "Epoch 17/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.7651 - acc: 0.5004 - val_loss: 1.8720 - val_acc: 0.4506\n",
            "Epoch 18/80\n",
            "8982/8982 [==============================] - 27s 3ms/step - loss: 1.7414 - acc: 0.5114 - val_loss: 1.8762 - val_acc: 0.4559\n",
            "Epoch 19/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.7308 - acc: 0.5171 - val_loss: 1.8803 - val_acc: 0.4421\n",
            "Epoch 20/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.7142 - acc: 0.5243 - val_loss: 1.9418 - val_acc: 0.4466\n",
            "Epoch 21/80\n",
            "8982/8982 [==============================] - 29s 3ms/step - loss: 1.7077 - acc: 0.5186 - val_loss: 1.8966 - val_acc: 0.4484\n",
            "Epoch 22/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.7041 - acc: 0.5254 - val_loss: 1.8919 - val_acc: 0.4501\n",
            "Epoch 23/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.6820 - acc: 0.5296 - val_loss: 1.9735 - val_acc: 0.4501\n",
            "Epoch 24/80\n",
            "8982/8982 [==============================] - 28s 3ms/step - loss: 1.6781 - acc: 0.5390 - val_loss: 1.9167 - val_acc: 0.4448\n",
            "Epoch 25/80\n",
            " 864/8982 [=>............................] - ETA: 23s - loss: 1.6593 - acc: 0.5394"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wov1xawUSzXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}